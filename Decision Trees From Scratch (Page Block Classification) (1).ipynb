{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb9e5ae-dbbd-49ca-9be0-29fb6f9680c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Read csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29fc667-91e0-4394-89d6-de4ed575e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Question is used to partition a dataset\n",
    "class Question:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    # Compare the feature value in an example to the feature value in this question\n",
    "    def match(self, example):\n",
    "        val = example[self.column]\n",
    "        return val >= self.value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Is Attribute[%s] >= %s\" % (self.column, self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "531d6922-3cf4-49f0-bcdb-17c8830e91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Leaf node classifies data\n",
    "class Leaf:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = self.__class_counts(rows)\n",
    "\n",
    "    # Counts the number of each type of example in a dataset\n",
    "    def __class_counts(self, rows):\n",
    "        counts = {}  # A dictionary of label -> count.\n",
    "        for row in rows:\n",
    "            label = row[-1] # The label is the last column\n",
    "            if label not in counts:\n",
    "                counts[label] = 0\n",
    "            counts[label] += 1\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff749842-bc0a-459d-b446-2c1ec6752e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Decision Node asks a question\n",
    "class Decision_Node:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29272aa2-4f7a-4e5d-84b4-4c48e2d1e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Decision Tree Classifier based on CART algorithm\n",
    "class CARTDecisionTreeClassifier:\n",
    "    # Counts the number of each type of example in a dataset\n",
    "    def __class_counts(self, rows):\n",
    "        counts = {}  # A dictionary of label -> count.\n",
    "        for row in rows:\n",
    "            label = row[-1] # Label is the last column\n",
    "            if label not in counts:\n",
    "                counts[label] = 0\n",
    "            counts[label] += 1\n",
    "        return counts\n",
    "\n",
    "    # Partitions a dataset\n",
    "    def __partition(self, rows, question):\n",
    "        true_rows, false_rows = [], []\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "\n",
    "    # Calculate the Gini Impurity for a list of rows\n",
    "    def __gini(self, rows):\n",
    "        counts = self.__class_counts(rows)\n",
    "        impurity = 1\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "            impurity -= prob_of_lbl**2\n",
    "        return impurity\n",
    "    \n",
    "    # Information Gain:\n",
    "    def __info_gain(self, left, right, current_uncertainty):\n",
    "        p = float(len(left)) / (len(left) + len(right))\n",
    "        return current_uncertainty - p * self.__gini(left) - (1 - p) * self.__gini(right)\n",
    "\n",
    "    # Main Algorithm\n",
    "    # Find the best question to ask\n",
    "    # Iterating over every feature / value and calculating the Information Gain\n",
    "    def __find_best_split(self, rows):\n",
    "        best_gain = 0  # keep track of the best information gain\n",
    "        best_question = None  # keep train of the feature / value that produced it\n",
    "        current_uncertainty = self.__gini(rows)\n",
    "        n_features = len(rows[0]) - 1  # number of columns\n",
    "\n",
    "        for col in range(n_features):  # for each feature\n",
    "\n",
    "            values = set([row[col] for row in rows])  # unique values in the column\n",
    "\n",
    "            for val in values:  # for each value\n",
    "\n",
    "                question = Question(col, val)\n",
    "\n",
    "                # try splitting the dataset\n",
    "                true_rows, false_rows = self.__partition(rows, question)\n",
    "\n",
    "                # Skip this split if it doesn't divide the dataset.\n",
    "                if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Calculate the information gain from this split\n",
    "                gain = self.__info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "                \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_question = gain, question\n",
    "\n",
    "        return best_gain, best_question\n",
    "\n",
    "    # Build the tree\n",
    "    def __build_tree(self, rows):\n",
    "        gain, question = self.__find_best_split(rows)\n",
    "\n",
    "        if gain == 0:\n",
    "            return Leaf(rows)\n",
    "        \n",
    "        true_rows, false_rows = self.__partition(rows, question)\n",
    "\n",
    "        true_branch = self.__build_tree(true_rows)\n",
    "        false_branch = self.__build_tree(false_rows)\n",
    "\n",
    "        return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "    def fit(self, training_data, training_label):\n",
    "        rows = np.hstack((training_data, training_label[:, None])) # Numpy concatenate 2D arrays with 1D array (shape problem)\n",
    "        self.__root = self.__build_tree(rows)\n",
    "    \n",
    "    # Add \"mode\" for different return from Leaf\n",
    "    # In detail mode it will return all the number of labels with format of {labels: counts}\n",
    "    # In oneAns mode it will return the label with the highest probability => In order to support sklearn.metrics\n",
    "    def __predictNode(self, testDataRow, node, mode='detail'):\n",
    "        # Base case: Reach a leaf\n",
    "        if isinstance(node, Leaf):\n",
    "            if mode == 'detail':\n",
    "                return node.predictions\n",
    "            else:\n",
    "                return max(node.predictions, key=node.predictions.get)\n",
    "        \n",
    "        if node.question.match(testDataRow):\n",
    "            return self.__predictNode(testDataRow, node.true_branch, mode)\n",
    "        else:\n",
    "            return self.__predictNode(testDataRow, node.false_branch, mode)\n",
    "\n",
    "    def predict(self, testing_data, mode='detail'):\n",
    "        # If only one row of testing data (i.e. Dimension = 1)\n",
    "        if testing_data.ndim == 1:\n",
    "            return self.__predictNode(testing_data, self.__root, mode)\n",
    "        else:\n",
    "            prediction = []\n",
    "            for row in testing_data:\n",
    "                prediction.append(self.__predictNode(row, self.__root, mode))\n",
    "            return prediction\n",
    "\n",
    "    def score(self, testing_data, testing_label, mode='detail'):\n",
    "        if mode == 'detail':\n",
    "            predict_label_dict = self.predict(testing_data)\n",
    "            totalRow = len(testing_label)\n",
    "            accuracy = 0\n",
    "            for i in range(totalRow):\n",
    "                total = sum(predict_label_dict[i].values()) * 1.0\n",
    "                for lbl in predict_label_dict[i].keys():\n",
    "                    # Probability of correct label\n",
    "                    if lbl == testing_label[i]:\n",
    "                        accuracy += predict_label_dict[i][lbl] / total\n",
    "            return float(accuracy/totalRow)\n",
    "        else:\n",
    "            predict_label = self.predict(testing_data, mode='oneAns')\n",
    "            total = len(testing_label)\n",
    "            correct = 0\n",
    "            for i in range(total):\n",
    "                if predict_label[i] == testing_label[i]:\n",
    "                    correct += 1\n",
    "            return float(correct/total)\n",
    "\n",
    "\n",
    "    def __print_tree(self, node, spacing=\" \"):\n",
    "        if isinstance(node, Leaf):\n",
    "            print(spacing + 'Predict', node.predictions)\n",
    "            return\n",
    "        \n",
    "        print(spacing + str(node.question))\n",
    "\n",
    "        print(spacing + '--> True')\n",
    "        self.__print_tree(node.true_branch, spacing + \"   \")\n",
    "\n",
    "        print(spacing + '--> False')\n",
    "        self.__print_tree(node.false_branch, spacing + \"   \")\n",
    "    \n",
    "    def visualization(self, spacing=\" \"):\n",
    "        self.__print_tree(self.__root, spacing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15c55be3-cd4d-440c-ab72-c43e1f68d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    inputData = pd.read_csv(path)\n",
    "    data = np.array(inputData.drop(['label'],axis= 1))\n",
    "    label = np.array(inputData['label'])\n",
    "    data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.3, random_state=87)\n",
    "    return data_train, label_train, data_test, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9d2970-a6a8-4e77-b6a7-4bf5b338374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDecisionTree(data_train, label_train):\n",
    "    clf = CARTDecisionTreeClassifier()\n",
    "    clf.fit(data_train, label_train)\n",
    "    return clf\n",
    "\n",
    "def testAccuracy(data_test, label_test, clf):\n",
    "    return clf.score(data_test, label_test)\n",
    "\n",
    "def evaluateModel(data_test, label_test, clf):\n",
    "    print(metrics.classification_report(label_test, clf.predict(data_test, mode='oneAns')))\n",
    "    print(metrics.confusion_matrix(label_test, clf.predict(data_test, mode='oneAns')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8358670-9989-4f7d-82ec-015ecdc9c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:04:20.076280\n",
      "Accuracy: 0.960820138043037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.98      0.98      1470\n",
      "           2       0.93      0.83      0.87       109\n",
      "           3       0.62      0.83      0.71         6\n",
      "           4       0.82      0.96      0.88        24\n",
      "           5       0.54      0.45      0.49        33\n",
      "\n",
      "    accuracy                           0.96      1642\n",
      "   macro avg       0.78      0.81      0.79      1642\n",
      "weighted avg       0.96      0.96      0.96      1642\n",
      "\n",
      "[[1446    6    3    3   12]\n",
      " [  16   90    0    2    1]\n",
      " [   1    0    5    0    0]\n",
      " [   1    0    0   23    0]\n",
      " [  17    1    0    0   15]]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "data_train, label_train, data_test, label_test = loadData('page-blocks.csv')\n",
    "# Train Model\n",
    "startTime = datetime.now()\n",
    "DecisionTreeModel = trainDecisionTree(data_train, label_train)\n",
    "print('Training time:', str(datetime.now() - startTime))\n",
    "\n",
    "# Test Accuracy\n",
    "print('Accuracy:', float(testAccuracy(data_test, label_test, DecisionTreeModel)))\n",
    "\n",
    "# Evaluate Model\n",
    "evaluateModel(data_test, label_test, DecisionTreeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0d24bc1-3758-4ad4-8124-c44fbb239446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
    "from sklearn.model_selection import train_test_split # Split training and testing data\n",
    "from sklearn import metrics # Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "960832a5-403b-45f4-add1-1e08cf069cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDecisionTree2(data_train, label_train):\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(data_train, label_train)\n",
    "    return clf\n",
    "\n",
    "def evaluateModel(data_test, label_test, clf):\n",
    "    print(metrics.classification_report(label_test, clf.predict(data_test)))\n",
    "    print(metrics.confusion_matrix(label_test, clf.predict(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6634f67b-19dc-40bd-962c-67edbe2cce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.066394\n",
      "Accuracy: 0.9622411693057247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.99      0.98      1470\n",
      "           2       0.88      0.83      0.85       109\n",
      "           3       0.67      0.67      0.67         6\n",
      "           4       0.85      0.96      0.90        24\n",
      "           5       0.61      0.42      0.50        33\n",
      "\n",
      "    accuracy                           0.96      1642\n",
      "   macro avg       0.80      0.77      0.78      1642\n",
      "weighted avg       0.96      0.96      0.96      1642\n",
      "\n",
      "[[1449    9    2    2    8]\n",
      " [  16   90    0    2    1]\n",
      " [   2    0    4    0    0]\n",
      " [   1    0    0   23    0]\n",
      " [  16    3    0    0   14]]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "data_train, label_train, data_test, label_test = loadData('page-blocks.csv')\n",
    "\n",
    "# Train Model\n",
    "startTime = datetime.now()\n",
    "DecisionTreeModel = trainDecisionTree2(data_train, label_train)\n",
    "print('Training time:', str(datetime.now() - startTime))\n",
    "\n",
    "# Test Accuracy\n",
    "print('Accuracy:', float(testAccuracy(data_test, label_test, DecisionTreeModel)))\n",
    "\n",
    "# Evaluate Model\n",
    "evaluateModel(data_test, label_test, DecisionTreeModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b76a1-cd41-47bf-a5c0-b22509c123f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
